[
  {
    "objectID": "tutorial_pages/simulate-for-preregistration.html",
    "href": "tutorial_pages/simulate-for-preregistration.html",
    "title": "Simulating data to check or preregister code",
    "section": "",
    "text": "Simulating data to check or preregister code\nOne of the simplest uses of simulations is to make a dataset on which you can run and therefore pre-specify your analytic code.\nFor example, let’s say you plan to collect an observational dataset and want to look at the effect of smoking on lung cancer. A typical protocol might state that the data will be analysed by logistic regression, adjusting for confounders. But which confounders exactly? How will each variable be coded? What type of logistic regression will you use?\nMaking a dataset that has the variables you expect your real dataset will have allows you to exactly state (in code rather than potentially ambiguous words) what you will do.\nThis is really useful if you want input from e.g. a statistician - they can look at your code and more clearly see what you are trying to do. It has the added benefit of forcing you to really think about what your dataset will look like! I’ve found this to be very useful in the past.\nIt’s very easy to make a dataset. Let’s take a simple example. We are interested in only 4 variables:\n\nsmoking status\nlung cancer\nsex\nage\n\nHere is the top of the simulated dataset.\n \n\n\nYOUR TURN:\n\nCan you recreate it? Try it yourself!\nHINT: use the data.frame(), sample(), and rnorm() functions.\nNow you’ve made a dataset, try to run a logistic regression on your data with lung cancer as the outcome.\nDo you face any error message? Does the data need to be in a specific format for statistical models to run?\n\n\nOnce we have a working model, we can look at the summary and make sure it behaves as we expected. And we can share the code with collaborators or reviewers.\nYou could combine this approach with the sampling approaches you learned in the power/alpha simulation session to look at power for more complex analyses like this.\n \n\nAnd that’s it! We have written down our code in a way that is totally unambiguous. This practice is useful for any project: you can include the exact code that you plan to use in a preregistration, and reviewers will be able to verify that you did what you planned.\nA real example of a simple simulation like this, used in the submission of a registered report, can be found in the rmd file here.\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Tutorial",
      "Simulate to prepare a preregistration"
    ]
  },
  {
    "objectID": "tutorial_pages/sample-size-n.html",
    "href": "tutorial_pages/sample-size-n.html",
    "title": "Sample size n",
    "section": "",
    "text": "Sample size n\nHow many values should you generate within a simulation? Let’s explore.\nIf I draw 10 data points from a normal distribution of mean 0 and sd 1, or N(0,1), after setting the seed to 10 (for no specific reason), here is the distribution of the values I get:\n1 sim of N(0,1) with n=10\n\n\nand if I replicate this simulation 24 times, here are the distributions of the 10 values pseudo-randomly sampled from N(0,1):\n24 sims of N(0,1) with n=10\n \n\nNote that because we are drawing from N(0,1), we expect the mean of the values drawn (mean(x), blue lines) to be very closed to 0, the mean of the normal distribution we sample from (red dashed lines).\n\nHow distributed are the means and standard deviations of the 24 simulations of 10 sampled values from N(0,1)?\nDistributions of the means and SDs from 24 sims N(0,1) with n=10\n \n\nNow, let’s do the same with a sample size n of 1000.\n24 sims of the same distribution N(0,1) with n=1000\n \n\nDistributions of the means and SDs from 24 sims N(0,1) with n=1000\n \n\n\nConclusion\nThe sample size within a simulation affects the precision with which the parameters of that distribution can be estimated.\nWhat should determine the sample size within your simulation?\n–&gt; a sample size that is relevant to the context of the simulation, e.g. the sample size you will be able to reach in your study, the minimum sample size that would allow you to detect the smallest effect of interest (as determined by a power analysis, which we will cover in a moment).\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Tutorial",
      "Sample size `n`"
    ]
  },
  {
    "objectID": "tutorial_pages/repeat.html",
    "href": "tutorial_pages/repeat.html",
    "title": "Repetition",
    "section": "",
    "text": "Repetition\nThe function * replicate(nrep, expression) repeats the expression provided nrep times.\ne.g. replicate(10, mean(rnorm(100))) reads: ‘draw 100 values from a normal distribution with a mean 0 and sd 1 (the default values), calculate the mean of these 100 values, and do all that 10 times.’\n\nYOUR TURN:\nIn your local exercise script:\nReplicate 1000 times the mean of 10 values drawn from a unifrom distribution between 0 and 10.\nReplicate 100 times the mean of 50 values drawn from a normal distribution of mean 10 and standard deviation 5.\nMake a histogram of each of your results, are the distributions looking as expected?\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Tutorial",
      "Repeat"
    ]
  },
  {
    "objectID": "tutorial_pages/random-numbers-generators.html",
    "href": "tutorial_pages/random-numbers-generators.html",
    "title": "Random number generators",
    "section": "",
    "text": "Random number generators\nR contains several functions to generate random numbers.\nType ?function in your consol to get information on the function’s arguments (i.e. the values that must be provided to obtain the function’s result).\nThe function\n- sample(x, n, replace=FALSE) draws n values from a given vector x without replacement (by default) .\nSampling without replacement means that when you repeatedly draw e.g. 1 item from a pool of items, any item selected during the first draw is not available for selection during the second draw, and the first and second selected items are not in the pool to select from during the third draw, etc. Sampling with replacement means that all the original options are available at each draw.\n\nYOUR TURN:\nSample 100 values between 3 and 103 with replacement.\nFor this, open the file ./exercise_script.R from the root of your local repository (with or without answers), review the examples if needed, complete the exercise, and check out the proposed answer.\n\nThe following functions draw n values from distributions with the specified parameters\n* runif(n, min, max) draws n values from a uniform distribution with the specified min and max\n* rpois(n, lambda) draws n values from a poisson distribution with the specified lambda\n* rnorm(n, mean, sd) draws n values from a normal distribution with the specified mean and standard deviation\n* rbinom(n, prob) draws n values from a binomial distribution with the specified probability\n\nYOUR TURN:\nDraw 100 values from a normal distribution with a mean of 0 and a sd of 1.\nDraw 50 values from a normal distribution with a mean of 10 and sd of 5.\nDraw 1000 values from a poisson distribution with a lambda of 50.\nDraw 30 values from a uniform distribution between 0 and 10.\nTry it out in your local exercise script.\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Tutorial",
      "Random Number Generators"
    ]
  },
  {
    "objectID": "tutorial_pages/number-of-simulations-nrep.html",
    "href": "tutorial_pages/number-of-simulations-nrep.html",
    "title": "Number of simulations nrep",
    "section": "",
    "text": "Number of simulations nrep\nSampling theory applies to the number of simulations nrep just as much as the sample size n within a simulation.\nmeans and SDs from 24 sims N(0,1) with n=10\n \n\nNow, let’s do the same with a number of repeats nrep of 1000.\nmeans and SDs from 1000 sims N(0,1) with n=10\n \n\n\nConclusion\nThe number of simulations needs to be a big enough number to obtain a good representation of the distribution of the simulation results, e.g. 1000.\n\nYOUR TURN:\nThe code generating the data and plots presented above are included in your exercice script. Feel free to modify the parameters of the functions that simulate data and plot the results to better understand the principles presented in these two pages, but, at this stage, there is no need to fully understand the code that generates the plots.\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Tutorial",
      "Number of simulations `nrep`"
    ]
  },
  {
    "objectID": "tutorial_pages/general-structure.html",
    "href": "tutorial_pages/general-structure.html",
    "title": "General structure of a simulation",
    "section": "",
    "text": "General structure of a simulation\n\ndefine what type of data and variables need to be simulated, i.e. their distribution, their class (e.g. factor vs numerical value), sample sizes (within a dataset, and number of replicates), what will need to vary (e.g. the strength of relationship)\ngenerate data, random data or data including an effect (e.g. an imposed correlation between two variables)\nrun the statistical test you think is appropriate, and record the relevant statistic (e.g. p-value)\nreplicate step 2 and 3 to get the distribution of the statistic of interest\ntry out different parameter sets (explore the parameter space for which results are similar)\nanalyze and interpret the combined results of many simulations within each set of parameters. For instance, check that you only get a significant result in 5% of the simulations (if alpha = 0.05) when you simulated no effect; and that you get at a significant result in 80% of the simulations (if you targeted a power of 80%) when you simulated an effect\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Tutorial",
      "General structure"
    ]
  },
  {
    "objectID": "tutorial_pages/download-repo.html",
    "href": "tutorial_pages/download-repo.html",
    "title": "Make this repository a local RStudio project",
    "section": "",
    "text": "You have two options to fetch this material:\n\n\nFork and clone this repository (here is a reminder on how to do this)\n\n\n\n1) Download the repository\nPlease download the GitHub repository that we are using today: https://github.com/lmu-osc/Introduction-Simulations-in-R\n \n\nOnce the .zip file downloaded, extract it and place the folder in the desired directory (e.g. Documents).\n2) Turn it into a RStudio project\nIf you do not have R or RStudio installed, please follow these instructions first.\nOpen RStudio, and go to ‘File’, ‘New Project…’, and select ‘Existing Directory’.\n \n\nSelect the downloaded (and extracted) folder, by clicking on ‘Browse’, then select ‘Create Project’.\n \n\nIn the panel containing the ‘Files’ tab, find the exercise sheet, and open it by double clicking on it.",
    "crumbs": [
      "Tutorial",
      "Download the material"
    ]
  },
  {
    "objectID": "tutorial_pages/download-repo.html#a.-you-know-version-control-with-git-and-github",
    "href": "tutorial_pages/download-repo.html#a.-you-know-version-control-with-git-and-github",
    "title": "Make this repository a local RStudio project",
    "section": "",
    "text": "Fork and clone this repository (here is a reminder on how to do this)",
    "crumbs": [
      "Tutorial",
      "Download the material"
    ]
  },
  {
    "objectID": "tutorial_pages/download-repo.html#b.-you-do-not-know-version-control-andor-simply-want-to-download-a-copy-of-this-material",
    "href": "tutorial_pages/download-repo.html#b.-you-do-not-know-version-control-andor-simply-want-to-download-a-copy-of-this-material",
    "title": "Make this repository a local RStudio project",
    "section": "",
    "text": "1) Download the repository\nPlease download the GitHub repository that we are using today: https://github.com/lmu-osc/Introduction-Simulations-in-R\n \n\nOnce the .zip file downloaded, extract it and place the folder in the desired directory (e.g. Documents).\n2) Turn it into a RStudio project\nIf you do not have R or RStudio installed, please follow these instructions first.\nOpen RStudio, and go to ‘File’, ‘New Project…’, and select ‘Existing Directory’.\n \n\nSelect the downloaded (and extracted) folder, by clicking on ‘Browse’, then select ‘Create Project’.\n \n\nIn the panel containing the ‘Files’ tab, find the exercise sheet, and open it by double clicking on it.",
    "crumbs": [
      "Tutorial",
      "Download the material"
    ]
  },
  {
    "objectID": "tutorial_pages/check-power.html",
    "href": "tutorial_pages/check-power.html",
    "title": "Checking power through simulations",
    "section": "",
    "text": "Checking power through simulations\nThe power of a statistical test tells us the probability that the test correctly rejects the null hypothesis. In other words, if we only examine true effects, the power is the proportion of tests that will (correctly) reject the null hypothesis. Often, the power is set to 0.8, though, as with alpha = 0.05, this is an arbitrary choice.\nGenerally, we want to do power analysis before collecting data, to work out the sample size we need to detect some effect. If we are calculating a required sample size, the power analysis can also be called a sample size calculation.\nTaking the example of a t-test, we need to understand a few parameters:\n\nn, the sample size\ndelta, the difference in means that you want to be able to detect. Deciding what this value should be is tricky. You might rely on estimates from the literature (though bear in mind they are likely to be inflated), or you can use a ‘minimally important difference’: you specify the threshold below which you do not think a difference is interesting enough to be worth detecting. In a clinical trial, this might be the smallest difference that a patient would care about, for example.\nsd, the standard deviation. Usually this needs to be estimated from the literature or from pilot studies.\nsig.level, the alpha, as discussed previously.\npower, the power as defined above.\n\nYou can calculate any one of these parameters, given all of the others. We usually want to specify, delta, sd, sig.level and power and calculate the required sample size.\nWe can calculate the required sample size for a t.test using:\npower.t.test(n = NULL, delta = 0.5, sd = 1, sig.level = 0.05, power = 0.8)\nNotice that n = NULL, so this parameter is calculated.\nThe sample size n we need given this set of parameters, is 64 per group.\nJust as we can check the alpha of our test by sampling from the same distribution (i.e. simulating data without an effect), we can check the power by sampling from different distributions (i.e. simulating data with an effect).\nIf we sample values from two normal ditributions with different means (e.g. N(0,1) and N(0.5,1)), what is the minimum sample size we need to detect a significant difference in means with a t.test, 80% of the time?\n\nYOUR TURN:\nUse your simulation skills to work out the power through simulation. Write a function which:\n\nDraws n values from a random normal distribution with mean1, and another n values from a normal distribution with mean2\nCompares the means of these two samples with a t-test and extracts the p.value\n\nReplicate the function 1000 times using the parameters used in the power calculation above (that used the power.t.test function)\nCalculate the proportion of p-values that are &lt;0.05\n\np-values of t tests comparing means from 1000 sims N(0,1) and N(0.5, 1) with n=64\n \n\nThe proportion of correctly rejected null hypotheses in the simulation is close to 0.8, which is what we would expect.\nUsing simulations for power analysis is not really necessary for simple examples like a t-test, though it is useful to check your understanding.\nWhen analyses become complex and it is hard or impossible to determine a sample size analytically (i.e. you can’t calculate it, or there’s no suitable function to use), then simulations are an indispensible tool.\nA simple example of a power analysis like the one you’ve just done can be found in the “Power analysis” section of this paper: * Blanco, David, et al (2020). “Effect of an editorial intervention to improve the completeness of reporting of randomised trials: a randomised controlled trial.” BMJ open 10.5: e036799. https://doi.org/10.1136/bmjopen-2020-036799\nA complete self-paced tutorial to simulate data for power analysis of complex statistical designs can be found here: * https://lmu-osc.github.io/Simulations-for-Advanced-Power-Analyses/\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Tutorial",
      "Simulate to check power"
    ]
  },
  {
    "objectID": "tutorial_pages/basic-principles.html",
    "href": "tutorial_pages/basic-principles.html",
    "title": "Basic principles",
    "section": "",
    "text": "Basic principles\nBasically, a simulation consist in\n1) Generating n random numbers from a known distribution\n2) Repeating this nrep number of times\nOnce you know how to do this, the questions we will explore are:\n1) what sample size n should we use within a simulation?\n2) how many simulations nrep should we run?\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Tutorial",
      "Basic Principles"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introduction to Simulations in R",
    "section": "",
    "text": "This tutorial was created by Malika Ihle based on materials from Joel Pick, Hadley Wickham, Kevin Hallgren, and with contributions from James Smith.\nIt is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License.\n\n\n\n\nHave R and RStudio installed. If you don’t, follow these instructions\n\nKnow some R basics (e.g. how to select a value in a data.frame, how to create a vector). If you don’t, visit the tutorial: https://lmu-osc.github.io/introduction-to-R/\n\n\n\n\n\nWatch this 30 min introduction to credible research, which contextualise the importance of simulations for reliable research.\nRead Hallgren A. K. 2013. Conducting simulation studies in the R programming environment. Tutor Quant Methods Psychol. ; 9(2): 43–60.\n\n\n\n\n\n\nThe self-paced tutorial (pages linked below) will alternate presentation of concepts and simple exercises for you to try to apply them in R. Each time you see written YOUR TURN, switch to your local copy of the exercise script (you can chose between a file with or without the solutions depending on e.g. your level of familiarity with R), review the examples if needed, complete the exercise, and check out the proposed answer (which often contains additional tips). Come back to the online tutorial and after finishing one page, you can navigate to the next page linked at the bottom to continue. The exercise script contains code for all the exercises and code that generates the plots that appear in the online tutorial, all in order of appearance in the tutorial.\nIt is necessary that you work through the sections of the tutorial in order. Please read the blurbs of each sections below to get an overview of this workshop. Then click on the first page ‘Download the material’ and follow along by navigating to the next page linked at the bottom of each page!\n\n\n\n\nDownload the material - Get this tutorial onto your machine\nDefinition - what are simulations?\nPurpose - what can we use simulations for?\nBasic Principles - what do we need to create a simulation?\nRandom Number Generators - how to generate random numbers in R?\nRepeat - how to repeat the generation of random numbers multiple times?\nSetting the seed - how can you generate the same random numbers?\nSample size n - how many values should you generate within a simulation?\nNumber of simulations nrep - how many repeats of a simulation should you run?\nDry rule - how to write your own functions?\nSimulate to check alpha - write your first simulation and check the rate of false-positive findings.\n\nSimulate to check power - simulate data to perform a power analysis.\n\nSimulate to prepare a preregistration - simulate data to test statistical analyses before preregistering them.\n\nGeneral structure - what is the general structure of a simulation?\nLimitations - what are the limitations to simulations?\nReal-life example - what are real life examples of simulations?\nAdditional resources - what resource can help you write your own simulation?",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#about-this-work",
    "href": "index.html#about-this-work",
    "title": "Introduction to Simulations in R",
    "section": "",
    "text": "This tutorial was created by Malika Ihle based on materials from Joel Pick, Hadley Wickham, Kevin Hallgren, and with contributions from James Smith.\nIt is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#prerequisites",
    "href": "index.html#prerequisites",
    "title": "Introduction to Simulations in R",
    "section": "",
    "text": "Have R and RStudio installed. If you don’t, follow these instructions\n\nKnow some R basics (e.g. how to select a value in a data.frame, how to create a vector). If you don’t, visit the tutorial: https://lmu-osc.github.io/introduction-to-R/",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#prior-to-the-session-optional-preparation-to-get-familiarised-with-the-subject",
    "href": "index.html#prior-to-the-session-optional-preparation-to-get-familiarised-with-the-subject",
    "title": "Introduction to Simulations in R",
    "section": "",
    "text": "Watch this 30 min introduction to credible research, which contextualise the importance of simulations for reliable research.\nRead Hallgren A. K. 2013. Conducting simulation studies in the R programming environment. Tutor Quant Methods Psychol. ; 9(2): 43–60.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#self-paced-workshop",
    "href": "index.html#self-paced-workshop",
    "title": "Introduction to Simulations in R",
    "section": "",
    "text": "The self-paced tutorial (pages linked below) will alternate presentation of concepts and simple exercises for you to try to apply them in R. Each time you see written YOUR TURN, switch to your local copy of the exercise script (you can chose between a file with or without the solutions depending on e.g. your level of familiarity with R), review the examples if needed, complete the exercise, and check out the proposed answer (which often contains additional tips). Come back to the online tutorial and after finishing one page, you can navigate to the next page linked at the bottom to continue. The exercise script contains code for all the exercises and code that generates the plots that appear in the online tutorial, all in order of appearance in the tutorial.\nIt is necessary that you work through the sections of the tutorial in order. Please read the blurbs of each sections below to get an overview of this workshop. Then click on the first page ‘Download the material’ and follow along by navigating to the next page linked at the bottom of each page!\n\n\n\n\nDownload the material - Get this tutorial onto your machine\nDefinition - what are simulations?\nPurpose - what can we use simulations for?\nBasic Principles - what do we need to create a simulation?\nRandom Number Generators - how to generate random numbers in R?\nRepeat - how to repeat the generation of random numbers multiple times?\nSetting the seed - how can you generate the same random numbers?\nSample size n - how many values should you generate within a simulation?\nNumber of simulations nrep - how many repeats of a simulation should you run?\nDry rule - how to write your own functions?\nSimulate to check alpha - write your first simulation and check the rate of false-positive findings.\n\nSimulate to check power - simulate data to perform a power analysis.\n\nSimulate to prepare a preregistration - simulate data to test statistical analyses before preregistering them.\n\nGeneral structure - what is the general structure of a simulation?\nLimitations - what are the limitations to simulations?\nReal-life example - what are real life examples of simulations?\nAdditional resources - what resource can help you write your own simulation?",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "tutorial_pages/check-alpha.html",
    "href": "tutorial_pages/check-alpha.html",
    "title": "Using simulations to check alpha",
    "section": "",
    "text": "Using simulations to check alpha\nIn most quantitative sciences we accept a type 1 error rate of “0.05”, which is often called the alpha or significance level. This value tells us the probability of rejecting the null hypothesis (i.e. of finding an effect) given that the null hypothesis is true.\nIn other words, if there is no true effect (e.g. no difference between two groups), we would expect our null hypothesis of no effect to be rejected (incorrectly), alpha% of the time.\nIf you draw from the same normal distribution twice, will the mean of the two samples differ significantly in 5% of the cases?\n\nYOUR TURN:\nFigure out how to do a t-test in R\nGenerate two vectors of 10 values drawn from N(0,1) and compare them with a t-test\nFigure out how to extract the p-value from that object (explore your R object with the functions str or names)\nWrite a function simT that generates two vectors of n values drawn from a N(0,1), compare them with a t-test and return the p-value\nRepeat with nrep=20 and draw a histogram for n=10\nRepeat with nrep=100 and draw a histogram for n=10\n\np-values of t-tests comparing means from 20 or 100 sims N(0,1) with n=10\n \n\nIn the first case, where nrep = 20, we expect 1 out of the 20 tests to be significant (5%). In my case, I did! How many did you get?\nIn the second case, where nrep = 100, we expect 5 out of the 100 tests to be significant. In my case, I got 6. How many did you get?\nAre those deviations meaningful? Significant?\n\nYOUR TURN:\nPlot the output of the function simT with nrep=1000 and n=10 Plot the output of the function simT with nrep=1000 and n=100\n\np-values of t-tests comparing means from 1000 sims N(0,1) with n=10 or n=100\n \n\nIn both cases, we expect 50 out of the 1000 tests to be significant by chance (i.e. with a p value under 0.05). In my simulations, I get 40 and 45 false positive results, for n=10 and 100, respectively. How many did you get?\nThese proportions are not significantly different from 5%.\nprop.test(45, 1000, p = 0.05, alternative = \"two.sided\", correct = TRUE)\n1-sample proportions test with continuity correction\ndata: 45 out of 1000, null probability 0.05\nX-squared = 0.42632, df = 1, p-value = 0.5138\nIt is important to note that, although alpha = 0.05 is commonly used, this is an arbitrary choice and you should consider what is an appropriate type 1 error rate for your particular investigation.\nAltough it isn’t necessary to check that a statistical analysis as simple as a t-test does not yield more than 5% of false-positive results, when the structure of the data is complex and analysed with more advanced models (e.g. when explanatory variables are mathematically linked to each other, and are combined in a mixed-effect models), this may allow to compare different modelling approach and select the one that does not produce more than 5% false positive results.\nSuch complex example where simulations is the only viable approach to construct a statistical model that does not lead to spurious effects can be found in this paper: * Ihle, Malika, et al (2020). “Measuring Up to Reality: Null Models and Analysis Simulations to Study Parental Coordination Over Provisioning Offspring.” Frontiers in Ecology and Evolution. https://doi.org/10.3389/fevo.2019.00142\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Tutorial",
      "Simulate to check alpha"
    ]
  },
  {
    "objectID": "tutorial_pages/definition.html",
    "href": "tutorial_pages/definition.html",
    "title": "Definition",
    "section": "",
    "text": "Definition\n“A computer simulation (or”sim”) is an attempt to model a real-life or hypothetical situation on a computer so that it can be studied to see how the system works. By changing variables in the simulation, predictions may be made about the behavior of the system. It is a tool to virtually investigate the behavior of the system under study”\n      Wikipedia\n“A computer simulation is the generation of random data to build up an understanding of the real data and the statistical models we use to analyze them”\n      Malika\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Tutorial",
      "Definition"
    ]
  },
  {
    "objectID": "tutorial_pages/dry-rule.html",
    "href": "tutorial_pages/dry-rule.html",
    "title": "Do not Repeat Yourself - DRY rule",
    "section": "",
    "text": "Following the WET rule will:\n\nIncrease the difficulty of change\n\nDecrease clarity\n\nLeads to opportunities for inconsistency\n To prevent duplication and follow the DRY rule, we can write custom functions.\n\nFunctions are ‘self contained’ sets of commands that accomplish a specific task.\nFunctions usually ‘take in’ data or parameter values (these inputs are called ‘function arguments’), process it, and ‘return’ a result. You’ve already used several functions in this tutorial; for example rnorm(n, mean, sd), where n, mean, and sd are inputs and the result is a random sample from the normal distribution. The only difference here is that you are writing the function yourself. Once a function is written, it can be used over and over again by calling its name, just like other functions such as rnorm().\nTo write your own function, use the function function:\nAwesomeFunctionName &lt;- function(argument1, argument2,…) {  \n  do stuff here  \n}\nTo build up a function, start by writing the “stuff” to test that it works outside the function.\n\nYOUR TURN:\nCreate a function that draws a histogram of nrep mean(rnorm(100))\nModify your function to draw a histogram of nrep mean(rnorm(n))\n\nNote that it is useful to define nrep outside of the function, so users of your script can more easily change that value e.g. from a low number (to verify the script runs without error) to a large number (to obtain reliable results).",
    "crumbs": [
      "Tutorial",
      "Dry rule"
    ]
  },
  {
    "objectID": "tutorial_pages/dry-rule.html#vs.-write-everything-twice---wet-rule",
    "href": "tutorial_pages/dry-rule.html#vs.-write-everything-twice---wet-rule",
    "title": "Do not Repeat Yourself - DRY rule",
    "section": "",
    "text": "Following the WET rule will:\n\nIncrease the difficulty of change\n\nDecrease clarity\n\nLeads to opportunities for inconsistency\n To prevent duplication and follow the DRY rule, we can write custom functions.\n\nFunctions are ‘self contained’ sets of commands that accomplish a specific task.\nFunctions usually ‘take in’ data or parameter values (these inputs are called ‘function arguments’), process it, and ‘return’ a result. You’ve already used several functions in this tutorial; for example rnorm(n, mean, sd), where n, mean, and sd are inputs and the result is a random sample from the normal distribution. The only difference here is that you are writing the function yourself. Once a function is written, it can be used over and over again by calling its name, just like other functions such as rnorm().\nTo write your own function, use the function function:\nAwesomeFunctionName &lt;- function(argument1, argument2,…) {  \n  do stuff here  \n}\nTo build up a function, start by writing the “stuff” to test that it works outside the function.\n\nYOUR TURN:\nCreate a function that draws a histogram of nrep mean(rnorm(100))\nModify your function to draw a histogram of nrep mean(rnorm(n))\n\nNote that it is useful to define nrep outside of the function, so users of your script can more easily change that value e.g. from a low number (to verify the script runs without error) to a large number (to obtain reliable results).",
    "crumbs": [
      "Tutorial",
      "Dry rule"
    ]
  },
  {
    "objectID": "tutorial_pages/limitations.html",
    "href": "tutorial_pages/limitations.html",
    "title": "Limitations to simulations",
    "section": "",
    "text": "Limitations to simulations\n\nassumptions made regarding variables might not be true, e.g. the distribution of supposedly normally distributed data may not be quite normal (have a back-up analysis plan!)\nparameter space unknown (explore it a bit, use previous observations to be at least in a relevant range)\ncomputational power and time (use research software engineer staff on campus to optimize code, use parallel core processing, use server services on campus, etc.)\nsimulations might be redundant with mathematical demonstrations (I don’t mind, still useful for me!)\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Tutorial",
      "Limitations"
    ]
  },
  {
    "objectID": "tutorial_pages/purpose.html",
    "href": "tutorial_pages/purpose.html",
    "title": "Purpose",
    "section": "",
    "text": "Purpose\nYou can use computer simulations to:\n\nTest your statistical intuition or demonstrate mathematical properties you cannot easily anticipate\n\ne.g. test whether when supposedly random data are generated, there is no more than 5% of significant effects for a variable in a model\n\n\nUnderstand sampling theory, probability distributions or test whether you understand the underlying processes of your system\n\ne.g. see whether simulated data drawn from specific distribution are comparable to real data\n\n\nPerform power analyses\n\ne.g. assess whether the sample size (within a replicate) is high enough to detect an effect simulated, in more than 80% of the cases\n\n\nPerform bootstrapping to get a confidence interval around a parameter estimate\n\ni.e. bootstrapping means to sample with replacement (i.e. all the original options to draw from are available at each draw) in an observed dataset. Doing this generates new ‘simulated’ datasets. With each of them, one can run the statistical analysis made on the observed dataset, saving each time the parameter estimate of interest. After doing this multiple time, you will obtain a confidence interval for the parameter of interest\n\n\nPrepare a pre-analysis plan\n\ne.g. in order to be confident about the (confirmatory) statistical analyses you may wish to commit to before data collection, through a preregistration or registered report, practicing the analyses on a simulated dataset is very helpful! If you are still unsure about the most appropriate statistical test to apply to your data, providing a simulated dataset to a statistician or mentor will allow them to provide concrete suggestions! The simulation code containing the analyses of simulated data can be submitted along your preregistration or registered report for reviewers to exactly understand what analyses you intend on performing. Once you get your real data, you may simply plug them in this code and get the results of your confirmatory analyses immediatly!\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Tutorial",
      "Purpose"
    ]
  },
  {
    "objectID": "tutorial_pages/real-life-example.html",
    "href": "tutorial_pages/real-life-example.html",
    "title": "Real life example",
    "section": "",
    "text": "Real life example\nThis is a walk through one relatively simple simulation written to check whether a\ngeneralized linear model on a contingency table of counts (poisson distribution) would provide the same results as a\ngeneralized linear model with one line per observation and the occurence of the variable of interest coded as Yes/No (binomial distribution).\nI created this code while preparing my preregistration for a simple behavioral ecology experiment:\nMethods for independently manipulating palatability and color in small insect prey (article, OSF preregistration)\nThe R script screenshoted below can be found in the folder Ihle2020.\n\nThis walk through will use the steps as defined in the page ‘general structure’\n\ndefine sample sizes (within a dataset, and number of replicates), experimental design (fixed dataset structure, e.g. treatment groups, factors) and parameters that will need to vary (here, the strength of the effect)\n\n\ngenerate data (here, using sample() and the probabilities defined in step 1 and format it in two different ways to accomodate the two statistical tests to be compared.\n\n\nrun the statistical test and save the parameter estimate of interest for that iteration. Here, this is done for both statistical tests to be compared.\n\n\nreplicate step 2 (data simulation) and 3 (data analyses) to get the distribution of the parameter estimates by wrapping these steps in a function\ndefinition of the function at the beginning:  \n output returned from the function at the end:\n \n replicate the function nrep number of times. Here pbreplicate is used to provide a bar of progress for R to run this command.\n \n\nexplore the parameter space. Here, vary the probabilities of sampling between 0 and 1 depending on the treatment group category.\n\n\nanalyze and interpret the combine results of many simulations. In this case, the results of the two models were qualitatively the same (comparison of results for a few simulations), and both models gave the same expected 5% false positive results when no effect were simulated. Varying the effect (the probability of sampling 0 or 1 depending on the experimental treatment) allowed to find the minimum effect size for which the number of positive results is over 80% of the tests.\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Tutorial",
      "Real-life example"
    ]
  },
  {
    "objectID": "tutorial_pages/resources.html",
    "href": "tutorial_pages/resources.html",
    "title": "Resources",
    "section": "",
    "text": "https://lmu-osc.github.io/Simulations-for-Advanced-Power-Analyses/\n\n\n\n\nThe article suggested for getting familiarised with the topic prior to the session, i.e. Hallgren A. K. 2013. Conducting simulation studies in the R programming environment. Tutor Quant Methods Psychol. ; 9(2): 43–60, contains accompanying R scripts and CSV data files which you can peruse in the Hallgren2013 folder of this repository. It contains:\n\nAnnotated R syntax file for Example 1: “novel question.R”\n\nAnnotated R syntax file for Example 2: “power analysis.R”\n\nAnnotated R syntax file for Example 3: “bootstrapping.R”\nCSV dataset generated in Example 1, which is also used later in Example 2: “novel_question_output.csv”\n\nCSV dataset used in Example 3: “mediation_raw_data.csv”\n\n\n\n\nDepending on the type of simulation that would be useful for you, these articles may be of interest:\n\nJohnson, P.C.D., Barry, S.J.E., Ferguson, H.M. and Müller, P. (2015). Power analysis for generalized linear mixed models in ecology and evolution. Methods Ecol Evol, 6: 133-142. https://doi.org/10.1111/2041-210X.12306\nBlanco, David, et al (2020). “Effect of an editorial intervention to improve the completeness of reporting of randomised trials: a randomised controlled trial.” BMJ open 10.5: e036799. https://doi.org/10.1136/bmjopen-2020-036799\n\nIn the “Power analysis” section, there is a simple example of a power simulation. R code is provided in the supplementary material.\n\nGetting started simulating data in R: some helpful functions and how to use them. https://aosmith.rbind.io/2018/08/29/getting-started-simulating-data/\n\nThis blog gives a great overview of how to start simulating more complex datasets, including step by step explanations of relevant R functions\n\nPrive, F., Aschard, H., Ziyatdinov, A. and Blum, M.G.B. (2018). Efficient analysis of large-scale genome-wide data with two R packages: bigstatsr and bigsnpr. Bioinformatics, 34(16), 2018, 2781–2787. https://doi.org/10.1093/bioinformatics/bty185\nRonnegard, L., et al. (2016). Increasing the power of genome wide association studies in natural populations using repeated measures – evaluation and implementation. Methods in Ecology and Evolution 2016, 7, 792–799. https://doi.org/10.1111/2041-210X.12535\nDalpiaz, D. (2020) Applied Statistics with R, Chapter 7 Simple Linear Regression, section 6 Simulating SLR. https://daviddalpiaz.github.io/appliedstats/simple-linear-regression.html#simulating-slr\n\n\n\n\n\nhttps://rpubs.com/bbolker/simpower\nhttps://cran.r-project.org/web/packages/simstudy/vignettes/simstudy.html\nhttps://debruine.github.io/faux/\nhttps://github.com/simsem/simsem/wiki/Vignette\nhttps://cran.r-project.org/web/packages/simglm/vignettes/tidy_simulation.html\nhttps://rpsychologist.com/therapists-effects-longitudinal",
    "crumbs": [
      "Tutorial",
      "Additional resources"
    ]
  },
  {
    "objectID": "tutorial_pages/resources.html#follow-up-self-paced-tutorial-on-simulation-of-data-analyses-for-advanced-power-analyses",
    "href": "tutorial_pages/resources.html#follow-up-self-paced-tutorial-on-simulation-of-data-analyses-for-advanced-power-analyses",
    "title": "Resources",
    "section": "",
    "text": "https://lmu-osc.github.io/Simulations-for-Advanced-Power-Analyses/",
    "crumbs": [
      "Tutorial",
      "Additional resources"
    ]
  },
  {
    "objectID": "tutorial_pages/resources.html#hallgren-2013",
    "href": "tutorial_pages/resources.html#hallgren-2013",
    "title": "Resources",
    "section": "",
    "text": "The article suggested for getting familiarised with the topic prior to the session, i.e. Hallgren A. K. 2013. Conducting simulation studies in the R programming environment. Tutor Quant Methods Psychol. ; 9(2): 43–60, contains accompanying R scripts and CSV data files which you can peruse in the Hallgren2013 folder of this repository. It contains:\n\nAnnotated R syntax file for Example 1: “novel question.R”\n\nAnnotated R syntax file for Example 2: “power analysis.R”\n\nAnnotated R syntax file for Example 3: “bootstrapping.R”\nCSV dataset generated in Example 1, which is also used later in Example 2: “novel_question_output.csv”\n\nCSV dataset used in Example 3: “mediation_raw_data.csv”",
    "crumbs": [
      "Tutorial",
      "Additional resources"
    ]
  },
  {
    "objectID": "tutorial_pages/resources.html#other-articles",
    "href": "tutorial_pages/resources.html#other-articles",
    "title": "Resources",
    "section": "",
    "text": "Depending on the type of simulation that would be useful for you, these articles may be of interest:\n\nJohnson, P.C.D., Barry, S.J.E., Ferguson, H.M. and Müller, P. (2015). Power analysis for generalized linear mixed models in ecology and evolution. Methods Ecol Evol, 6: 133-142. https://doi.org/10.1111/2041-210X.12306\nBlanco, David, et al (2020). “Effect of an editorial intervention to improve the completeness of reporting of randomised trials: a randomised controlled trial.” BMJ open 10.5: e036799. https://doi.org/10.1136/bmjopen-2020-036799\n\nIn the “Power analysis” section, there is a simple example of a power simulation. R code is provided in the supplementary material.\n\nGetting started simulating data in R: some helpful functions and how to use them. https://aosmith.rbind.io/2018/08/29/getting-started-simulating-data/\n\nThis blog gives a great overview of how to start simulating more complex datasets, including step by step explanations of relevant R functions\n\nPrive, F., Aschard, H., Ziyatdinov, A. and Blum, M.G.B. (2018). Efficient analysis of large-scale genome-wide data with two R packages: bigstatsr and bigsnpr. Bioinformatics, 34(16), 2018, 2781–2787. https://doi.org/10.1093/bioinformatics/bty185\nRonnegard, L., et al. (2016). Increasing the power of genome wide association studies in natural populations using repeated measures – evaluation and implementation. Methods in Ecology and Evolution 2016, 7, 792–799. https://doi.org/10.1111/2041-210X.12535\nDalpiaz, D. (2020) Applied Statistics with R, Chapter 7 Simple Linear Regression, section 6 Simulating SLR. https://daviddalpiaz.github.io/appliedstats/simple-linear-regression.html#simulating-slr",
    "crumbs": [
      "Tutorial",
      "Additional resources"
    ]
  },
  {
    "objectID": "tutorial_pages/resources.html#use-of-r-packages-to-run-simulations",
    "href": "tutorial_pages/resources.html#use-of-r-packages-to-run-simulations",
    "title": "Resources",
    "section": "",
    "text": "https://rpubs.com/bbolker/simpower\nhttps://cran.r-project.org/web/packages/simstudy/vignettes/simstudy.html\nhttps://debruine.github.io/faux/\nhttps://github.com/simsem/simsem/wiki/Vignette\nhttps://cran.r-project.org/web/packages/simglm/vignettes/tidy_simulation.html\nhttps://rpsychologist.com/therapists-effects-longitudinal",
    "crumbs": [
      "Tutorial",
      "Additional resources"
    ]
  },
  {
    "objectID": "tutorial_pages/seed.html",
    "href": "tutorial_pages/seed.html",
    "title": "Setting the seed",
    "section": "",
    "text": "Setting the seed\n\nset.seed()\n\nComputers in general, and R specifically, can, in fact, only provide pseudo random number generators.\nA pseudorandom number generator’s number sequence is completely determined by its seed, i.e. a number used to initialize that sequence.\nThus, if a pseudorandom number generator is reinitialized with the same seed, it will produce the same sequence of numbers. You can set the seed (with any arbitrary number) at the beginning of a script, and, if commands drawing random numbers are ran in the exact same order, they will provide the same output in subsequent runs.\nThis is useful for sharing code and reproduce simulations, as well as for debugging code.\n\nYOUR TURN:\nIn your local exercise script:\nPlay around with the function set.seed() by running and modifying the examples provided (e.g. compare outputs with and without seeds, change the seed number)\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Tutorial",
      "Setting the seed"
    ]
  }
]